{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0a0021-ae35-4311-c38b-7262256afa62"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(inputs.shape[1], requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63842065-f2f6-4132-a19c-2e5eea807f5f"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6614, 0.2669, 0.0617], requires_grad=True)\n",
            "tensor([0.6213], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X, w, b):\n",
        "  z = X @ w.T + b\n",
        "  return 1 / (1 + torch.exp(-z))"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_pred_proba = model(inputs, w, b)\n",
        "target_pred_proba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoGt96P8fWXf",
        "outputId": "5321f472-a2ae-4ebe-f2cd-d0869f58bb82"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Підозріло виглядає те, що всі передбачення дорівнюють рівно 1, хоча ми мали б отримати імовірності від 0 до 1."
      ],
      "metadata": {
        "id": "Uvbcw0MrjqMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "    epsilon = 1e-7\n",
        "    predicted_probs = torch.clamp(predicted_probs, epsilon, 1 - epsilon)  # Ensure probabilities are between epsilon and 1-epsilon\n",
        "    return -torch.mean(true_labels * torch.log(predicted_probs) + (1 - true_labels) * torch.log(1 - predicted_probs))"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(target_pred_proba, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wle2fclsiHC2",
        "outputId": "ddea7650-27fa-436a-8694-1f004c0c2b3b"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.3770, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e867190-511d-460c-8e92-f55af5f0b114"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Градієнти дорівнюють 0."
      ],
      "metadata": {
        "id": "u95zyLGKkp2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_pred_proba = model(inputs, w, b)\n",
        "target_pred_proba"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38528bba-c6bd-41c2-819e-05870212dbaa"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5174],\n",
              "        [0.5220],\n",
              "        [0.5244],\n",
              "        [0.5204],\n",
              "        [0.5190]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(target_pred_proba, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN30k8VIviGK",
        "outputId": "89a9abd1-288c-4b59-ed42-4728e130b67a"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6829, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIJcEeIMvrMT",
        "outputId": "80034b64-a7f4-47f7-9717-389643b08d7b"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, w, b, y, lr=0.001, epochs=1000):\n",
        "  for epoch in range(epochs):\n",
        "    y_pred_proba = model(X, w, b)\n",
        "    loss = binary_cross_entropy(y_pred_proba, y)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      w.data = w.data - lr * w.grad\n",
        "      b.data = b.data - lr * b.grad\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "\n",
        "    if epoch == 0 or epoch % 100 == 99:\n",
        "      print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "  return w, b\n",
        "\n",
        "w, b = gradient_descent(inputs, w, b, targets)"
      ],
      "metadata": {
        "id": "mObHPyE06qsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e974be6-ef4f-43d9-c7bf-371552590dfd"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6829456686973572\n",
            "Epoch 99, Loss: 0.19809281826019287\n",
            "Epoch 199, Loss: 0.16247422993183136\n",
            "Epoch 299, Loss: 0.13817240297794342\n",
            "Epoch 399, Loss: 0.11979919672012329\n",
            "Epoch 499, Loss: 0.10536112636327744\n",
            "Epoch 599, Loss: 0.09374729543924332\n",
            "Epoch 699, Loss: 0.08423858135938644\n",
            "Epoch 799, Loss: 0.076337531208992\n",
            "Epoch 899, Loss: 0.06968771666288376\n",
            "Epoch 999, Loss: 0.06402736902236938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = (model(inputs, w, b) > 0.5).int()\n",
        "print(preds)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFs3tVBSnWMe",
        "outputId": "219923db-061f-4955-8c20-1e7410304917"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1]], dtype=torch.int32)\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм досягнув високої точності з втратами 0.064."
      ],
      "metadata": {
        "id": "T7f7FgKLoDkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "# Data normalization\n",
        "inputs = (inputs - inputs.mean()) / inputs.std()\n",
        "\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5219e698-9fb3-4c1f-aaa9-e2c33d329cc8"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0717, -0.3106, -1.2662],\n",
              "         [ 0.6451,  0.5256, -0.4300],\n",
              "         [ 0.4858,  2.3573, -0.6690]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa87e4b4-ff4c-4273-c7d7-014df224f3ba"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.6451,  0.5256, -0.4300],\n",
              "         [-0.0717, -0.3106, -1.2662],\n",
              "         [ 0.6451,  0.5256, -0.4300],\n",
              "         [ 1.0831, -1.2662, -1.5051],\n",
              "         [-0.2309,  0.8442, -0.1911]]),\n",
              " tensor([[1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogReg(torch.nn.Module):\n",
        "    # Initialize the layers\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "        self.act = nn.Sigmoid() # Activation function\n",
        "\n",
        "    # Perform the computation\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "model = LogReg()"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "loss_fn = func.binary_cross_entropy"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(model(inputs), targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E84JOO8Tr9p",
        "outputId": "61c10a83-d762-4bfc-b7ac-dd53559358d4"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9873, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ми ще не вчили модель, а лише обчислили втрати використовуючи рандомно ініціалізовані ваги."
      ],
      "metadata": {
        "id": "egb1ckcSsLQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()  # Calculate gradients\n",
        "            opt.step()  # Update weights\n",
        "            opt.zero_grad()  # Reset gradients\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Calculate epoch avg loss\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        if epoch == 0 or epoch % 100 == 99:\n",
        "          print(f'Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "cEHQH9qE626k"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 100 epochs\n",
        "loss = fit_return_loss(1000, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysveIzepUM88",
        "outputId": "a4d90852-6f7d-412b-98c3-c85d0b86b02d"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], Loss: 0.9386\n",
            "Epoch [99/1000], Loss: 0.0666\n",
            "Epoch [199/1000], Loss: 0.0359\n",
            "Epoch [299/1000], Loss: 0.0246\n",
            "Epoch [399/1000], Loss: 0.0187\n",
            "Epoch [499/1000], Loss: 0.0150\n",
            "Epoch [599/1000], Loss: 0.0126\n",
            "Epoch [699/1000], Loss: 0.0108\n",
            "Epoch [799/1000], Loss: 0.0095\n",
            "Epoch [899/1000], Loss: 0.0084\n",
            "Epoch [999/1000], Loss: 0.0076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ahm_JIWqURBP",
        "outputId": "7b0b2cad-9ad5-4b99-feaa-77aaef651219"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = (model(inputs) > 0.5).int()\n",
        "print(preds)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd8OP153UWUM",
        "outputId": "90afdbc9-815d-45d9-aa94-1169af764d39"
      },
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1]], dtype=torch.int32)\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qahjw1hFXjEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}